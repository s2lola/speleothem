{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use this paper with we want train for only one speleothem\n",
    "https://arxiv.org/pdf/1605.06065.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeleothemDating(Dataset):\n",
    "    def __init__(self, annotations_file, normalize=True):\n",
    "        self.speleothem = pd.read_csv(annotations_file)\n",
    "        \n",
    "        if normalize:\n",
    "            self.normalize()\n",
    "\n",
    "        self.x_label = [\"depth_dating\", \"latitude\", \"longitude\", \"elevation\", \"entity_id_site\"]\n",
    "        self.y_label = [\"corr_age\"]\n",
    "        \n",
    "        x = self.speleothem.loc[:, self.x_label].values\n",
    "        y = self.speleothem.loc[:, self.y_label].values\n",
    "        \n",
    "        self.x_train = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.speleothem)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n",
    "    \n",
    "    def normalize(self):\n",
    "        std_scaler = StandardScaler()\n",
    "        self.speleothem = pd.DataFrame(std_scaler.fit_transform(self.speleothem), columns=self.speleothem.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speleothem = SpeleothemDating(\"training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(speleothem))\n",
    "test_size = len(speleothem) - train_size\n",
    "train_dataset, test_dataset = random_split(speleothem, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1170,  0.1898,  0.9685, -0.4712,  0.7594],\n",
       "         [-0.6995, -0.5377,  1.0168, -0.6539, -1.4606],\n",
       "         [ 0.1221, -0.9713,  1.0854, -0.2323, -0.4842],\n",
       "         [-0.3142,  1.2524, -2.0357, -0.8928,  0.9454],\n",
       "         [-0.2237,  0.8835, -0.3863, -0.7593, -1.6465],\n",
       "         [-0.5694,  0.0352,  0.8667, -0.5105,  1.7009],\n",
       "         [-0.3775,  0.1898,  0.7341,  0.8076, -0.9492],\n",
       "         [-0.5898,  0.7690, -1.9138,  0.8217, -0.0774],\n",
       "         [-0.3556,  0.7188, -0.0943, -0.9476, -1.0421],\n",
       "         [-0.0428, -0.0800, -1.6160,  0.3073, -0.1123],\n",
       "         [ 0.5571,  0.9077, -0.1730, -0.7115, -1.3327],\n",
       "         [ 0.0659, -1.5048,  0.1424, -0.9771,  1.2360],\n",
       "         [-0.0795,  0.9077, -0.1730, -0.7115, -1.3327],\n",
       "         [ 0.6630,  0.5972, -0.4914, -0.8647, -1.2281],\n",
       "         [-0.4163,  0.9316, -0.1179, -0.2393,  1.2825],\n",
       "         [-0.7046,  1.6250, -0.2114, -0.7733, -1.3908]]),\n",
       " tensor([[-0.6667],\n",
       "         [-0.6557],\n",
       "         [-0.2582],\n",
       "         [-0.6503],\n",
       "         [ 0.0971],\n",
       "         [-0.6024],\n",
       "         [-0.5108],\n",
       "         [-0.6647],\n",
       "         [-0.5786],\n",
       "         [-0.3761],\n",
       "         [-0.0852],\n",
       "         [ 2.4389],\n",
       "         [-0.0288],\n",
       "         [ 0.3629],\n",
       "         [-0.5832],\n",
       "         [-0.6101]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MultipleRegression, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 16)\n",
    "        self.layer_2 = nn.Linear(16, 32)\n",
    "        self.layer_3 = nn.Linear(32, 16)\n",
    "        self.layer_out = nn.Linear(16, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultipleRegression(num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultipleRegression(\n",
       "  (layer_1): Linear(in_features=5, out_features=16, bias=True)\n",
       "  (layer_2): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (layer_3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # if batch % 10 == 0:\n",
    "        #     loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss_total/batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "    return test_loss\n",
    "    # print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss_train: 0.6019951998842535, loss_test: 0.5680917636914686\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss_train: 0.577360453222085, loss_test: 0.5478264410387386\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss_train: 0.5596636367478857, loss_test: 0.5315844199874185\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss_train: 0.5440450710830865, loss_test: 0.5098337709903717\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss_train: 0.5353831554314604, loss_test: 0.5083975266326558\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss_train: 0.5253931848263299, loss_test: 0.4927056247537786\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss_train: 0.5151748481310077, loss_test: 0.5182167251001705\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss_train: 0.5104886864622434, loss_test: 0.5021070038730447\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss_train: 0.5083806174634783, loss_test: 0.4904240136796778\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss_train: 0.4941555221944495, loss_test: 0.4670653928409923\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_train = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    loss_test = test(test_dataloader, model, loss_fn)\n",
    "    print(f\"loss_train: {loss_train}, loss_test: {loss_test}\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speleothem-D0j3gjp0-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88385cb4d3649893f5ed111600523dce48bee70e0a73c9054031d68280bb1b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
