{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use this paper with we want train for only one speleothem\n",
    "https://arxiv.org/pdf/1605.06065.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeleothemDating(Dataset):\n",
    "    def __init__(self, annotations_file, normalize=True):\n",
    "        self.speleothem = pd.read_csv(annotations_file)\n",
    "        \n",
    "        if normalize:\n",
    "            self.normalize()\n",
    "\n",
    "        self.x_label = [\"depth_dating\", \"latitude\", \"longitude\", \"elevation\", \"entity_id_site\"]\n",
    "        self.y_label = [\"corr_age\"]\n",
    "        \n",
    "        x = self.speleothem.loc[:, self.x_label].values\n",
    "        y = self.speleothem.loc[:, self.y_label].values\n",
    "        \n",
    "        self.x_train = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.speleothem)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n",
    "    \n",
    "    def normalize(self):\n",
    "        std_scaler = StandardScaler()\n",
    "        self.speleothem = pd.DataFrame(std_scaler.fit_transform(self.speleothem), columns=self.speleothem.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "speleothem = SpeleothemDating(\"training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(speleothem))\n",
    "test_size = len(speleothem) - train_size\n",
    "train_dataset, test_dataset = random_split(speleothem, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3331,  0.8161, -1.5272, -0.5049,  0.5153],\n",
       "         [-0.2709,  0.3119,  0.9551, -0.4150,  0.3410],\n",
       "         [ 2.0435,  0.3352,  0.9514, -0.3658,  0.6083],\n",
       "         [-0.6485,  0.6338,  1.0029,  0.6811,  1.1430],\n",
       "         [-0.6407,  0.1898,  0.7341,  0.8076, -0.9492],\n",
       "         [-0.4869,  0.1898,  0.7341,  0.8076, -0.9492],\n",
       "         [ 0.0481,  0.6243, -1.8175,  2.3675, -1.1351],\n",
       "         [ 0.0889, -1.9935,  1.7569, -0.5485,  0.2131],\n",
       "         [ 0.2395,  0.9455, -0.2804,  1.6508, -0.2402],\n",
       "         [-0.6551, -0.8740, -1.3540,  1.7491,  0.7129],\n",
       "         [-0.4444,  0.6155, -0.4060, -0.8998,  1.3987],\n",
       "         [-0.3372,  0.7690, -1.9138,  0.8217, -0.0774],\n",
       "         [ 3.8679, -0.5396,  1.0162, -0.7944, -0.3448],\n",
       "         [-0.1412,  0.4562,  0.9120,  0.3158,  0.9105],\n",
       "         [ 1.5395,  0.8148, -0.4410, -0.8857,  1.6312],\n",
       "         [-0.0132,  0.1154,  0.3095,  0.1190,  0.0737]]),\n",
       " tensor([[-0.6508],\n",
       "         [-0.6038],\n",
       "         [-0.6262],\n",
       "         [-0.5349],\n",
       "         [-0.5436],\n",
       "         [-0.5273],\n",
       "         [-0.6539],\n",
       "         [-0.6464],\n",
       "         [ 0.4252],\n",
       "         [ 0.9463],\n",
       "         [ 0.2003],\n",
       "         [-0.6428],\n",
       "         [-0.5013],\n",
       "         [ 0.5474],\n",
       "         [-0.5887],\n",
       "         [ 3.3682]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MultipleRegression, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 16)\n",
    "        self.layer_2 = nn.Linear(16, 32)\n",
    "        self.layer_3 = nn.Linear(32, 16)\n",
    "        self.layer_out = nn.Linear(16, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultipleRegression(num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultipleRegression(\n",
       "  (layer_1): Linear(in_features=5, out_features=16, bias=True)\n",
       "  (layer_2): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (layer_3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.651941  [   16/ 3460]\n",
      "loss: 0.870161  [  176/ 3460]\n",
      "loss: 0.642314  [  336/ 3460]\n",
      "loss: 0.655393  [  496/ 3460]\n",
      "loss: 0.538557  [  656/ 3460]\n",
      "loss: 0.637014  [  816/ 3460]\n",
      "loss: 0.674752  [  976/ 3460]\n",
      "loss: 0.603464  [ 1136/ 3460]\n",
      "loss: 0.520536  [ 1296/ 3460]\n",
      "loss: 0.451280  [ 1456/ 3460]\n",
      "loss: 0.972002  [ 1616/ 3460]\n",
      "loss: 1.123011  [ 1776/ 3460]\n",
      "loss: 0.816682  [ 1936/ 3460]\n",
      "loss: 0.503058  [ 2096/ 3460]\n",
      "loss: 0.607497  [ 2256/ 3460]\n",
      "loss: 0.653267  [ 2416/ 3460]\n",
      "loss: 0.729381  [ 2576/ 3460]\n",
      "loss: 0.561396  [ 2736/ 3460]\n",
      "loss: 0.591647  [ 2896/ 3460]\n",
      "loss: 0.486574  [ 3056/ 3460]\n",
      "loss: 0.538101  [ 3216/ 3460]\n",
      "loss: 0.593084  [ 3376/ 3460]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.563323 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.452288  [   16/ 3460]\n",
      "loss: 0.414511  [  176/ 3460]\n",
      "loss: 1.188594  [  336/ 3460]\n",
      "loss: 0.480943  [  496/ 3460]\n",
      "loss: 0.760850  [  656/ 3460]\n",
      "loss: 0.309972  [  816/ 3460]\n",
      "loss: 0.624749  [  976/ 3460]\n",
      "loss: 0.588852  [ 1136/ 3460]\n",
      "loss: 0.468235  [ 1296/ 3460]\n",
      "loss: 0.711467  [ 1456/ 3460]\n",
      "loss: 0.327961  [ 1616/ 3460]\n",
      "loss: 0.623685  [ 1776/ 3460]\n",
      "loss: 0.712813  [ 1936/ 3460]\n",
      "loss: 1.478544  [ 2096/ 3460]\n",
      "loss: 0.455222  [ 2256/ 3460]\n",
      "loss: 0.542449  [ 2416/ 3460]\n",
      "loss: 0.997072  [ 2576/ 3460]\n",
      "loss: 0.306778  [ 2736/ 3460]\n",
      "loss: 0.295731  [ 2896/ 3460]\n",
      "loss: 0.823796  [ 3056/ 3460]\n",
      "loss: 0.434112  [ 3216/ 3460]\n",
      "loss: 0.867181  [ 3376/ 3460]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.552248 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.358364  [   16/ 3460]\n",
      "loss: 0.552642  [  176/ 3460]\n",
      "loss: 0.466771  [  336/ 3460]\n",
      "loss: 0.419231  [  496/ 3460]\n",
      "loss: 0.311541  [  656/ 3460]\n",
      "loss: 0.784560  [  816/ 3460]\n",
      "loss: 0.928706  [  976/ 3460]\n",
      "loss: 0.799688  [ 1136/ 3460]\n",
      "loss: 0.360312  [ 1296/ 3460]\n",
      "loss: 0.525222  [ 1456/ 3460]\n",
      "loss: 0.319228  [ 1616/ 3460]\n",
      "loss: 0.634288  [ 1776/ 3460]\n",
      "loss: 0.314572  [ 1936/ 3460]\n",
      "loss: 1.131626  [ 2096/ 3460]\n",
      "loss: 0.558273  [ 2256/ 3460]\n",
      "loss: 0.496367  [ 2416/ 3460]\n",
      "loss: 0.408065  [ 2576/ 3460]\n",
      "loss: 0.175309  [ 2736/ 3460]\n",
      "loss: 0.289254  [ 2896/ 3460]\n",
      "loss: 0.847948  [ 3056/ 3460]\n",
      "loss: 0.184790  [ 3216/ 3460]\n",
      "loss: 0.578990  [ 3376/ 3460]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.533660 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.492234  [   16/ 3460]\n",
      "loss: 0.617903  [  176/ 3460]\n",
      "loss: 0.455310  [  336/ 3460]\n",
      "loss: 0.153009  [  496/ 3460]\n",
      "loss: 0.605804  [  656/ 3460]\n",
      "loss: 0.420800  [  816/ 3460]\n",
      "loss: 0.683326  [  976/ 3460]\n",
      "loss: 0.511490  [ 1136/ 3460]\n",
      "loss: 0.411654  [ 1296/ 3460]\n",
      "loss: 0.922162  [ 1456/ 3460]\n",
      "loss: 0.421677  [ 1616/ 3460]\n",
      "loss: 0.675978  [ 1776/ 3460]\n",
      "loss: 0.713227  [ 1936/ 3460]\n",
      "loss: 0.527191  [ 2096/ 3460]\n",
      "loss: 0.410324  [ 2256/ 3460]\n",
      "loss: 0.811916  [ 2416/ 3460]\n",
      "loss: 0.300840  [ 2576/ 3460]\n",
      "loss: 0.430224  [ 2736/ 3460]\n",
      "loss: 0.679098  [ 2896/ 3460]\n",
      "loss: 0.554788  [ 3056/ 3460]\n",
      "loss: 0.413964  [ 3216/ 3460]\n",
      "loss: 0.965611  [ 3376/ 3460]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.526637 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.431034  [   16/ 3460]\n",
      "loss: 0.496115  [  176/ 3460]\n",
      "loss: 0.451966  [  336/ 3460]\n",
      "loss: 0.982694  [  496/ 3460]\n",
      "loss: 0.435454  [  656/ 3460]\n",
      "loss: 0.624447  [  816/ 3460]\n",
      "loss: 0.735213  [  976/ 3460]\n",
      "loss: 0.498240  [ 1136/ 3460]\n",
      "loss: 0.352808  [ 1296/ 3460]\n",
      "loss: 0.512414  [ 1456/ 3460]\n",
      "loss: 0.575720  [ 1616/ 3460]\n",
      "loss: 0.749555  [ 1776/ 3460]\n",
      "loss: 0.592302  [ 1936/ 3460]\n",
      "loss: 0.348168  [ 2096/ 3460]\n",
      "loss: 0.225083  [ 2256/ 3460]\n",
      "loss: 0.305278  [ 2416/ 3460]\n",
      "loss: 0.500054  [ 2576/ 3460]\n",
      "loss: 0.729400  [ 2736/ 3460]\n",
      "loss: 0.180831  [ 2896/ 3460]\n",
      "loss: 0.596927  [ 3056/ 3460]\n",
      "loss: 0.286280  [ 3216/ 3460]\n",
      "loss: 0.419777  [ 3376/ 3460]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.507259 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speleothem-D0j3gjp0-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88385cb4d3649893f5ed111600523dce48bee70e0a73c9054031d68280bb1b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
